<!DOCTYPE html>
<html lang="de">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Mirco Fuchs, Daniel Matthes, Patrick Frenzel">
    <meta name="publisher" content="Laboratory for Biosignal Processing">
    <meta name="copyright" content="Laboratory for Biosignal Processing">
    <meta name="description" content="Die Arbeitsgruppe Laboratory for Biosignal Processing ist spezialisiert auf die Erfassung, Verarbeitung und Analyse von Biosignalen. Im Fokus steht die Entwicklung innovativer und anwendungsnaher Lösungen.">
    <meta name="keywords" content="Computer Vision, KI, AI, Maschinelles Lernen, Machine Learning, Videoanalyse, Bildanalyse, kamerabasierte Anwendungen, Software, Firmware, Embedded, Systems, eingebettete, Systeme, Technologietransfer, Forschung, Entwicklung, Förderung, ZIM, HTWK, Leipzig, LaBP, Partner, Entwickler, Mittelstand, KMU, Beratung, Kooperation, Transfer, Forschungstransfer, Messen, Analyse, Auswertung, Analytics, Predictive Maintenance, Hochschule, Fördermittel">
    <meta name="page-topic" content="Forschung Technik">
    <meta name="audience" content="Alle, Experten, Fortgeschrittene, Profis">
    <meta http-equiv="content-language" content="de">
    <meta name="robots" content="index, follow">

    <title>Laboratory for Biosignal Processing</title>

    <!-- MapBox -->
    <script src='https://api.tiles.mapbox.com/mapbox.js/v2.2.1/mapbox.js'></script>
    <link href='https://api.tiles.mapbox.com/mapbox.js/v2.2.1/mapbox.css' rel='stylesheet' />

    <!-- Additional fonts -->
    <!--<link rel='stylesheet' href='http://fonts.googleapis.com/css?family=Raleway:400,300,700' type='text/css'>-->
    <link rel='stylesheet' href='http://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700' type='text/css'>

    <!-- FONT AWESOME (for Twitter Icon) -->
    <link rel="stylesheet" href="css/font-awesome.css">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>

    <!-- Customization CSS styles -->
    <link href="css/skeleton.css" rel="stylesheet">
    <link href="css/base.css" rel="stylesheet">
    <link href="css/main.css" rel="stylesheet">

    <script>
      function mailAddress(first, last) {
        var host = "htwk-leipzig.de";
        return first + "." + last + "@" + host;
      }

      function mailAddressStud(first, last) {
      	var host = "stud.htwk-leipzig.de";
	return first + "." + last + "@" + host;      
      }

      function mailAddressFTZ(name) {
        var host = "ftz.htwk-leipzig.de";
        return name + "@" + host;
      }
    </script>

  </head>

  <body data-spy="scroll" data-target="navbar">
    <div id="main">
      <nav>
        <ul>
          <li><a href="#intro">Start</a></li>
          <li><a href="#forschung">Forschung</a></li>
          <li><a href="#technologietransfer">Technologietransfer</a></li>
          <li><a href="#studenten">Studenten</a></li>
          <li><a href="#team">Team</a></li>
          <li><a href="#kontakt">Kontakt</a></li>
        </ul>
      </nav>

      <!=== Start ==>
      <section id="intro" class="section">
        <div class="container first-of-type">
<!--
          <a href="https://ergonomics-in-motion.com" target="_blank"><img src="./img/eim-banner.png"/></a>
-->
          <h1>Aktuelle Themenangebote / Thesis Projects</h1>
          Dear students,<br>
          please notice our <a href=#studenten>current offers for internships and thesis projects below</a>. Please contact us in case you are interested in one of these research topics.

          <br><br>
          Liebe Studierende,<br>
          bitte beachtet weiter unten unsere aktuellen <a href=#studenten>Themenangebote</a> für Abschlussarbeiten und Praktika. Die Angebote richtet sich vorzugsweise an StudentInnen mit Interessensgebieten im Bereich Computer Vision, Deep Learning und Softwareentwicklung.

          <h1>LABORATORY for BIOSIGNAL PROCESSING</h1>

					<img src="img/P1000822_16x9.jpg" style="display:block;margin-left:auto;margin-right:auto;">

          Das <em>Laboratory for Biosignal Processing</em> (LaBP) arbeitet schwerpunktmäßig an der Erfassung, Verarbeitung und Analyse von Bild-, Video- und Sensordaten. Im Fokus unserer Forschungs- und Entwicklungsarbeiten stehen innovativer, anwendungsnaher Lösungen für einen breiten Anwendungsbereich, insbesondere aber für Sportanwendungen und den medizinischen Bereich. Wir sind zugleich Kooperations- und Ansprechpartner für Unternehmen aller Branchen, die Bedarf an der Entwicklung technischer Lösungen in unseren Kompetenzfeldern haben.<br><br>

<!--
          Neuigkeiten aus der Arbeitsgruppe sowie Job- und Themenangebote für Praxisforschungs-, Bachelor- und Masterarbeiten
          finden Sie über unseren Twitter-Feed <i class="fa fa-twitter" aria-hidden="true"></i> <a href="https://twitter.com/labp_htwk" target="_blank">@LaBP_HTWK</a>.
-->

        </div>
      </section>

      <!=== Studenten ==>
      <section id="studenten" class="section">
        <div class="container">
          <h1>Studenten</h1>
          Ihr seid auf der Suche nach einem Thema für eure Bachelor- oder Masterarbeit? Ihr möchtet uns durch praktische Arbeit im Rahmen eurer Abschlussarbeit unterstützen? Wir bieten spannende Themen aus den Bereichen Computer Vision, Maschinelles Lernen, Algorithmen- und Softwareentwicklung (C/C++/Qt, Python).<br><br>

          Unabhängig von den hier ausgeschriebenen Themen vergeben wir ständig kleine und größere Projektarbeiten, mit denen ihr euer Wissen während der Vorlesungen, der Semesterferien oder eines Praktikums erweitern könnt. <a href="#kontakt">Nehmt bitte Kontakt mit uns auf</a>.<br>

	  <h2>Themen für Praktika & Graduierungsarbeiten</h2>
          <ul>
	    <li>Themen mit Anwendungen im Sport</li>
              <ul>
		<li>Kamerabasierte Zwischenzeitanalyse im Kanu-Slalom</li>
		<li>Technik- und Renntaktikanalyse im Kanu-Rennsport</li>
		<li>Video- und Sensorbasierte Technikanalyse im Rudern</li>
		<li>Videodatenanalyse im Tischtennis</li>
		<li>Kamerabasierte Analyse von Bewegungsmustern</li>      
	      </ul>
	    <li>Themen mit Bezug zur Medizin</li>		  
	      <ul>
		<li>Videobasierten Analyse bei Autismus-Spektrum-Störungen</li>
		<li>KI-basierte Aneurysmen-Segmentierung</li> 
		<li>Deep-Learning basierte Blutdruckbestimmung</li>      
	      </ul>
	    <li>Themen mit Bezug zu Architektur und Bau</li>
	      <ul>
		<li>Reinforcement-Learning zum Entwurf optimaler Verbindungselemente im Holzbau</li>      
	      </ul>
	    <li>Kontextübergreifende Themen</li>
	      <ul>
		<li>Evaluierung von Posenerkennungs- und Objektsegmentierungsverfahren (Pose-Machine & Mask R-CNN vs. YOLO v8)</li>      
		<li>Automatische Kalibrierung von Mehrkamerasystemen</li>
		<li>CV-Anwendungen unter Windows-Subsystem-for-Linux</li>      
	      </ul>
	    <li>Themen mit unmittelbaren Lehrbezug</li>
	      <ul>
		<li>Demo und Praktikum für eine Hyperspektralkamera </li>
		<li>Demo und Praktikum für eine Pan-Tilt-Zoom-Kamera</li>      
	      </ul>
	  </ul>

	  <!--
          <h2>Abschlussarbeiten&nbsp;&nbsp;<button data-toggle="collapse" class="btn btn-outline-secondary" data-target="#thesis">mehr...</button></h2>
          <div id="thesis" class="collapse">
            <div class="thesis">
            -->
              <h2>Abschlussarbeiten&nbsp;&nbsp;</h2>

              <strong>in Bearbeitung</strong>
              <ul>
		<li>Toni Volker Schoechert: <em>Bestimmung von Schlagfrequenzprofilen anhand von Videodaten im Kanu-Rennsport</em>, Bachelorarbeit</li>
		<li>Paula Schlegel: <em>Konzept und Erprobung einer App-basierten Videodatenanalyse in einer Client-Server-Anwendung am Beispiel der Technikbewertung im Kanu-Rennsport im Nachwuchsbereich</em>, Masterarbeit</li>
		<li>Jannik Sobisch: <em>Untersuchung von Verfahren und Methoden zur KI-basierten Diagnostik struktureller Erkrankungen des Gehirns</em>, Dissertation</li>       
		<li>Michael Francisco Bäumler: <em>Untersuchung von Algorithmen zur Analyse des Blutflusses in intrakraniellen Aneurysmen</em>, Praxisprojekt</li>
		<li>Paul Jürgens: <em>Aufbau, Inbetriebnahme und Erprobung eines DOBOT Magician</em>, Praxisforschungsprojekt</li>      
		<li>Bianca Reichard: <em>Untersuchung von Methoden und Verfahren zur automatischen, kontinuierlichen Schmerzerfassung in klinischen Anwendungen</em>, Dissertation</li>
              </ul>

	      <strong>2024</strong>
	      <ul>
		<li>Linda Vogel: <em>Erprobung von KI-Modellen zur videobasierte Fahrtechnikanalyse im Rudern</em>, Masterarbeit</li>
		<li>Henrietta Estorff: <em>Untersuchungen zur automatischen Bestimmung von Szenen- und Posenmarkern als Grundlage für vergleichende Streckenabschnittszeitanalysen im Kanu-Slalom</em>, Masterarbeit</li>
		<li>Nico Tietze: <em>Realisierung eines Demonstrators zur kamerabasierten Erfassung von Vitalparametern und Kopfposen mithilfe eines digitalen Spiegels</em>, Bachelorarbeit</li>      
		<li>Simon Langner: <em>Untersuchung von Segmentierungsverfahren für Anwendungen im Kanu-Rennsport</em>, Bachelorarbeit</li>
		<li>Sarah Rockstroh: <em>Erkennung von Schlagereignissen im Kanu-Rennsport mit Machine-Learning-Methoden</em>, Masterarbeit</li>
	      </ul>
		
	      <strong>2023</strong>
	      <ul>
		<li>Jannis Brakel: <em>Erkennung von Bahnbegrenzungen im Kanu-Rennsport</em>, Bachelorarbeit</li>
		<li>Julian Thomas Ziegler: <em>Erprobung eines RL-Ansatzes zur Bauteilerkennung</em>, Bachelorarbeit</li>
	      </ul>	
		
              <strong>2022</strong>
              <ul>
                <li>Maja Sester: <em>Automatische Detektion von Paddellinie und Handpositionen in Bildsequenzen für Technikanalysen im Kanu-Rennsport</em>, Masterarbeit.</li>
                <li>Paul Rudi Serdack: <em>Implementierung und Evaluation der PPG-basierten Blutdruckklassifikation mithilfe von Deep-Learning-Verfahren</em>, Masterarbeit.</li>
                <li>Franz Seebach: <em>Evaluierung einer kamerabasierten, markerlosen Skelettdatenerfassung zur Bewertung und Live-Rückkopplung der Ergonomie von Körperposen</em>, Masterarbeit.</li>
                <li>Matthew Leighton: <em>Feasibility of Automated Bird’s Eye View Estimation Using Person Detection in Indoor Bakery Scenes</em>, Bachelorarbeit.</li>
                <li>Clemens Seeger: <em>Implementierung und Evaluierung eines maschinellen Lernverfahrens zur Vorhersage der globalen Solarstrahlung am Boden mittels Satellitenbeobachtungen</em>, Bachelorarbeit.</li>
              </ul>

              <strong>2019</strong>
              <ul>
                <li>Marie-Sophie von Braun: <em>Anwendung und Optimierung von Deep-Learning-Verfahren zur automatischen Bestimmung trainingswissenschaftlicher Parameter aus Videodaten im Kanurennsport</em>, Bachelorarbeit.</li>
                <li>Romy Spangenberg: <em>Entwicklung und Evaluierung von Methoden für eine automatisierte, kontinuierliche Vermessung von Wildtieren in Stereo-Videodaten</em>, Masterarbeit.</li>
                <li>Peter Hornik: <em>Optimierung von Metaparametern beim Training von Convolutional Neural Networks</em>, Bachelorarbeit.</li>
                <li>Bianca Reichard: <em>Evaluierung von Verfahren zur kontinuierlichen Schmerzerfassung auf Basis kontaktlos erfasster Vital- und Aktivitätsdaten</em>, Masterarbeit.</li>
                <li>Robert Fromm: <em>Entwicklung und Erprobung eines Konzeptes zur Realisierung einer miniaturisierten Multisensorplattform zur synchronen Erfassung von Mehrkanalvideo- und Sensordaten</em>, Masterarbeit.</li>
                <li>Fabian Ohlig: <em>Entwicklung eines Softwaremoduls zur Klassifikation von Körperposen auf Basis von 2D-Skelettdaten</em>, Bachelorarbeit.</li>
                <li>Fabian Schrumpf: <em>Konzeption eines Verfahrens zur ähnlichkeitsbasierten hierarchischen Cluster-Analyse von Vitaldaten und dessen Validierung am Beispiel von Schmerzmittelgaben nach herzchirurgischen Eingriffen</em>, Dissertation.</li>

                <!--
                <li>Sven Schwass: <em>Evaluierung von Verfahren des maschinellen Lernens zur  ...</em>, Bachelorarbeit.</li>
              -->
              </ul>
              <strong>2018</strong>
              <ul>
                <li>Piet Wagner: <em>Entwicklung und Evaluierung von Bildanalyseverfahren zur Extraktion von Trainingsparametern aus Videodaten im Kanurennsport</em>, Bachelorarbeit.</li>
                <li>Jakob Timm: <em>Aufbau und Evaluierung eines Trackingsystems zur Erfassung von Bewegungsabläufen bei der Flächendekonatmination</em>, Masterarbeit.</li>
                <li>Leo Wawrzyniak: <em>Untersuchungen zur kamerabasierten Mimikerfassung mithilfe am Körper getragener Senorik auf Basis eines Fischaugenobjektives</em>, Bachelorarbeit.</li>
                <li>Maik Schälicke: <em>Evaluierung, Test und Optimierung von Convolutional Neural Networks zur Haltungserkennung aus 2D-Bilder</em>, Masterarbeit.</li>
              </ul>
              <strong>2017</strong>
              <ul>
                <li>Max Pfeiffer: <em>Aufbau und Evaluierung eines Sensorsystems für die Prozessanalyse bei Dekontaminationsvorgängen</em>, Bachelorarbeit.</li>
                <li>Tom Schönfelder: <em>Verfahren zur 3D-Haltungserfassung aus Videodaten in Echtzeit</em>, Masterarbeit.</li>
                <li>Christoph Mönch: <em>Entwicklung eines Demonstrationssystems für intraoperatives, multimodales Schmerzmonitoring</em>, Masterarbeit.</li>
                <li>Robert Fromm: <em>Entwicklung eines Kamera-basierten Point-of-Care-Demonstrationssystems</em>, Bachelorarbeit.</li>
                <li>Franz Anders: <em>Visualisierung kontinuierlicher, multimodaler Schmerz-Scores am Beispiel akustischer Signale</em>, Masterarbeit.</li>
                <li>Andre Hering: <em>Energieeffiziente Implementierung von kryptographischen Verfahren für eingebettete Systeme</em>, Masterarbeit.</li>
                <li>Georg Rokita: <em>Entwicklung eines Low-cost-Gateways für ein Low-Power-Wide-Area-Network</em>, Bachelorarbeit.</li>
              </ul>
              <strong>2016</strong>
              <ul>
                <li>Bianca Reichardt & Juliane Bauer: <em>Kamera-basierte Messung von Laufzeitunterschieden zwischen rPPG-Signalen in unterschiedlichen Gesichtsregionen</em>, Bachelorarbeit.</li>
                <li>Lukas Kuhlisch: <em>Entwicklung eines alternativen Systems zur Erfassung von Bewegungsabläufen bei der Flächen-Dekontamination</em>, Bachelorarbeit.</li>
                <li>Anne Mehlhorn: <em>Entwicklung von Verfahren zur automatisierten Bewertung und Visualisierung elektrokardiografischer Daten</em>, Bachelorarbeit.</li>
                <li>Niels Hesselbarth: <em>Implementierung und Evaluation von Verfahren zur Blutdruckschätzung aus photoplethysmographischen und elektrokardiographischen Signalen</em>, Bachelorarbeit.</li>
                <li>Gunnar Nitzold: <em>Entwicklung eines Systems zur optischen Erfassung von Bewegungsabläufen bei der Flächen-Dekontamination</em>, Bachelorarbeit.</li>
                <li>Arvid Goldau: <em>Entwicklung eines Embedded Systems zur Realisierung echtzeitfähiger signalabhängiger Prozessbeeinflussungen an Werkzeugmaschinen sowie einer adaptiven Geräteeinheit</em>, Masterarbeit.</li>
                <li>Martin Würkner: <em>Entwicklung eines Embedded System zur webbasierten Darstellung von Signalen einer Werkzeugmaschine sowie eines adaptiven Gerätes</em>, Masterarbeit.</li>
              </ul>
              <strong>2015</strong>
              <ul>
                <li>Christoph Mönch: <em>Entwicklung einer Software zur Erfassung der Herzfrequenz mittels remote Photoplethysmographie</em>, Bachelorarbeit.</li>
              </ul>
              <strong>2014</strong>
              <ul>
                <li>Thomas Goldermann: <em>Audiobasierte Erkennung von Atemgeräuschen</em>, Bachelorarbeit.</li>
                <li>Matthias Jahn: <em>Methoden zur Erfassung von Bewegungen mittels Intertialsensoren</em>, Bachelorarbeit.</li>
                <li>Markus Neubert: <em>Validierung eines Mehrkamera-Systems zur markerlosen Bewegungserfassung für ein Ergonomie-Feedback in Echtzeit</em>, Bachelorarbeit.</li>
                <li>Max Bach: <em>Entwicklung und Erprobung eines Systems zur berührungslosen Erfassung der Herzfrequenz</em>, Bachelorarbeit.</li>
                <li>Fabian Schrumpf: <em>Implementierung und Evaluation moderner Quelllokalisierungsverfahren auf Basis der Bayes’schen Inferenz</em>, Masterarbeit.</li>
                <li>Vivian Ehrlich: <em>Integration eines Beamformer-Verfahrens in eine EEG/MEG-Onlineverarbeitungstoolbox</em>, Bachelorarbeit.</li>
                <li>Riko Maschke: <em>Entwicklung und Integration von Regions-of-Interest bei der Echtzeitanalyse von Gehirnaktivität aus EEG- und MEG-Signalen</em>, Bachelorarbeit.</li>
              </ul>
              <strong>2012</strong>
              <ul>
                <li>Sebastian Spieß: <em>Konzept zur Implementierung digitaler Spiegel auf Basis einer eingebetteten Signalverarbeitungsplattform und Realisierung zweier Beispielanwendungen im kognitionswissenschaftlichen Kontext</em>, Masterarbeit.</li>
              </ul>
              <strong>2011</strong>
              <ul>
                <li>Patrick Frenzel: <em>Entwicklung von Hard- und Softwarekomponenten zur Realisierung drahtloser EKG- und EEG-Module als Basis multimodaler Analysen peripherphysiologischer Daten</em>, Masterarbeit.</li>
                <li>Tim Kähler: <em>Laufzeitkonfguration einer prioritätsorientierten, CPU/GPU basierten Filter-Pipeline zur Verarbeitung hochkanaliger EEG/MEG-Daten auf Basis der Visualisierungsplattform OpenWalnut</em>, Masterarbeit.</li>
              </ul>
              <strong>2010</strong>
              <ul>
                <li>Martin Speer: <em>Entwicklung eines Systemkonzeptes für drahtlo energieautarke Sensoren zur Ableitung und Übertragung physiologischer Signale</em>, Bachelorarbeit.</li>
                <li>Andreas Friedrich: <em>Implementierung GPU-basierter Algorithmen zur Lokalisierung und Visualisierung von Hirnaktivität aus EEG/MEG-Daten in Echtzeit</em>, Bachelorarbeit.</li>
              </ul>
              <!--
            </div>
          </div>
        -->
        </div>
      </section>	    
	    
      <!=== Forschung & Entwicklung ==>
      <section id="forschung" class="section">
        <div class="container">
          <h1>Forschung &amp; Entwicklung</h1>
        Im folgenden Abschnitt stellen wir Ihnen die Schwerpunkte unserer Forschungsarbeiten vor und präsentieren einige konkrete Ergebnisse und Anwendungsbeispiele. Lassen Sie sich inspirieren und <a href=#kontakt> kontaktieren Sie uns</a>, wenn Sie an weiteren Informationen interessiert sind oder Anwendungsmöglichkeiten in ihrem Bereich sehen.
        
<br><br>
Informationen zu Forschungsprojekten ab 2021 finden Sie hier: <a href="https://fing.htwk-leipzig.de/forschung-transfer/computervisionundmaschinelleslernen" target="_blank">https://fing.htwk-leipzig.de/forschung-transfer/computervisionundmaschinelleslernen</a>

<!--
	<h2>Themenbereiche&nbsp;&nbsp;<button data-toggle="collapse" class="btn btn-outline-secondary" data-target="#demo">mehr...</button></h2>

	<div id="demo" class="collapse">

<!--
          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingThree">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="false" aria-controls="collapseThree">
                  Internet der Dinge
                </a>
              </h3>
            </div>
            <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
              <div class="panel-body">
                Durch die Integration von Elektronik, Sensorik, Kommunikationsschnittstellen und vor allem von Analyseverfahren können inzwischen jederzeit und an jedem Ort unterschiedlichste Informationen erfasst, analysiert und weitergeleitet werden. Embedded Systems bilden den Grundbaustein für das ‚Internet der Dinge‘. Die Breitentechnologie Embedded Systems ist daher ein Treiber von Innovationen in verschiedensten Anwendungsbereichen.<br><br>

                Sowohl für den Bereich der Medizin und biomedizinischen Diagnostik als auch für andere Anwendungsbereiche konnte die Arbeitsgruppe bereits marktfähige Lösungen inklusive Hardware und Algorithmen entwickeln, darunter ein Temperaturcontroller für den Mikrofluidikbereich, sensorunterstützte Evaluation von Reinraumsäuberung und ein markerloses Bewegungserfassungssystem für ein Ergonomie-Feedback in Echtzeit.<br><br>

                Ihre Expertise in den Gebieten Internet of Things (IoT) und eingebettete Systeme befähigt die Arbeitsgruppe auch in der Beratung von Unternehmen und im Aufbau eines arbeitsfähigen Netzwerks aus potenziellen Anwendern, Produzenten und Entscheidern. Den Auftakt dazu stellte das zweitägige Innovationsforum "Embedded Innovation" im September 2015 dar, woraus weitere Veranstaltungen und ein Netzwerk auf Initiative der Arbeitsgruppe hervorgehen.<br><br>

              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingSeven">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseSeven" aria-expanded="false" aria-controls="collapseSeven">
                  Kamera-basierte Erfassung von Haltungs- & Bewegungsdaten / Skeletterkennung
                </a>
              </h3>
            </div>
            <div id="collapseSeven" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingSeven">
              <div class="panel-body">
                Mehr zu diesem Themenfeld erfahren Sie hier in Kürze. Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>


          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingFour">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseFour" aria-expanded="false" aria-controls="collapseFour">
                  Kamera-basierte Erfassung von Vitalparametern
                </a>
              </h3>
            </div>
            <div id="collapseFour" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingFour">
              <div class="panel-body">
                <h2>Prinzip Kontakt-basierter Vitalparametermessung mit optischen Sensoren</h2>
                Die Grundlage für die optische Bestimmung von Vitalparametern sind unterschiedliche Absorptionseigenschaften von oxygeniertem und deoxygeniertem Blut. Durchleuchtet man mithilfe eines Senders durchblutetes Gewebe mit Licht einer bestimmten Wellenlänge und erfasst mithilfe eines Lichtempfängers das Signal, welches nicht vom Gewebe absorbiert wird, dann lässt sich ein zur Herzmuskelkontraktion korreliertes Signal bestimmten. Dieses Signal entsteht, weil der Anteil von sauerstoffangereichertem Blut im durchleuchteten Volumen infolge des "Herzschlags" und dem damit verbundenen regelmäßigen Auswurf des von der Lunge kommenden Blutes in die Arterien systematisch variiert.<br><br>

                Dieses Prinzip ist die Grundlage für die schon seit Jahrzehnten in der Medizin eingesetzte Technik der Photoplethysmography (PPG), bei der mithilfe eines Finger-Clips, in dem sich eine Lichtquelle und ein -empfänger befinden, die sogenannten Blutvolumenkurve abgegriffen wird. Die PPG ist heute ein wichtiges diagnostisches Mittel. Sie ermöglicht neben der  Bestimmung der Pulsfrequenz und der Atemfrequenz auch die Schätzung des Blutdrucks (sowohl mit als auch ohne zusätzliche Sensorik wie beispielsweise dem Elektrokardiogramm) und ist gleichzeitig auch die Grundlage für die Bestimmung der Sauerstoffsättigung (SpO2-Messung).<br><br>

                Da es sich bei PPG um ein optisches Verfahren handelt, wurden in den letzten Jahren immer mehr Techniken entwickelt, um die Blutvolumenkurve auch aus größerer Entfernung - also ohne Finger-Clip mit direktem Körperkontakt - und häufig auch ohne zusätzliche Lichtquelle nur mithilfe einer Kamera zu erfassen.

                <h2>Prinzip kontaktloser Vitalparametermessung mittels Kamera</h2>
                Nach dem aktuellen Stand der Forschung sind verschiedene Verfahren beschrieben, um aus Kameradaten oder Videosequenzen unterschiedliche Vitalinformationen zu gewinnen. Dazu zählen insbesondere die Herzfrequenz und die Atemfrequenz, aber auch Korrelate zum Blutdruck und die Sauerstoffsättigung. Grundsätzlich basieren diese Verfahren darauf, bestimmte Farbintensitätsanderungen in den Videobildern zu analysieren, die mit der Änderung des zur Herz-Kreislauf-Aktivität korrelierten Blutflusses moduliert sind, oder infolge kleinster Bewegungen entstehen. Im folgenden Bild ist dies nochmals veranschaulicht.<br><br>
                <img src="img/kamera_PPG.png" style="display:block;margin-left:auto;margin-right:auto;">

                Ähnlich wie beim Finger-Clip-basierten PPG lassen sich aus dem sogenannten remote-PPG- (rPPG) oder imaging-PPG-Signal (iPPG) die Pulsfrequenz bestimmen. Die Atemfrequenz kann ebenfalls durch Analyse dieses Signals oder alternativ durch die Analyse der Bewegungsinformationen ermittelt werden.<br><br>

                Auch für die Kamera-basierte Bestimmung des Blutdrucks existieren erste Ansätze. So wurde beispielsweise am Laboratory for Biosignal Processing untersucht, inwieweit sich aus der Analyse von Laufzeitunterschieden der in verschiedenen Regionen des Gesichts bestimmbaren rPPG-Signale die Ausbreitungsgeschwindigkeit bestimmen und so indirekt auf den Blutdruck rückschließen lässt. Das folgende Bild verdeutlicht das Messprinzip.
                <img src="img/kamera_Blutdruck.png" style="display:block;margin-left:auto;margin-right:auto;">

                Die Weiterentwicklung dieser Kamera-basierten Technologien zur Bestimmung von Vitalparametern ist Gegenstand aktueller Forschungsarbeiten am LaBP. Darüber hinaus sind wir bestrebt, neue Anwendungsfelder zu erschließen. Die Kamera-basierte Vitaldatenerfassung bildet einen wichtigen Baustein für eines unserer weiteren Themenfelder, dem <a href=#headingSix>kontaklosen Schmerzmonitoring</a> und war Grundlage zur Entwicklung eines <a href=#headingNineteen>Vitalparameter-Monitors für Neugeborene.</a><br><br>

                Darüber hinaus sind die hier durchgeführten Arbeiten wesentlicher Bestandteil unserer <a href=#headingTwelve>Software-Plattform zur Kamera-basierten Erfassung von Vitalparametern und Mimik</a>, deren Funktionalität Sie in einer <a href=#headingSixteen>Web-Applikation anhand eigener Videos selbst ausprobieren</a> können. Die Software wurde auch bereits in der Praxis für die <a href=#headingThirteen> Entwicklung eines digitalen Spiegels</a> verwendet.

                <br><br>Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingFive">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseFive" aria-expanded="false" aria-controls="collapseFive">
                  Kamera-basierte Erfassung von Mimik
                </a>
              </h3>
            </div>
            <div id="collapseFive" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingFive">
              <div class="panel-body">
                Ende der 1970er Jahre wurde mit dem Facial Action Coding System (FACS) ein Beschreibungsframework für Mimik eingeführt (P. Ekman & W. Friesen, Facial Action Coding System: A Technique for the Measurement of Facial Movement, Consulting Psychologists Press, Palo Alto, 1978). Dabei wird das Gesicht in insgesamt 44 Merkmale zerlegt - den sogenannten Action Units (AUs). Beispiele für Action Units sind AU9, die das Rümpfen der Nase beschreibt, und AU15, die das Herabziehen der Mundwinkel kodiert. Daran ist ersichtlich, dass in eine AU Informationen aus unterschiedlichen Regionen einfließen können. In der unten stehenden Abbildung ist die Untegliederung des Gesichtes beispielhaft dargestellt. Je nachdem, wie stark das jeweilige Merkmal einer AU ausgeprägt ist, wird ihr auf einer 5-stufigen Skala eine Intensität zugeordnet. Durch die Kombination mehrerer AUs lassen sich bestimmte Gesichtsausdrücke charakterisieren. Zum Beispiel lässt sich so Information darüber gewinnen, ob Schmerzen, Freude, Wut, usw. empfunden werden. <br><br>

                <img src="img/kamera_Mimik.png" style="display:block;margin-left:auto;margin-right:auto;">

                Die Bewertung der Merkmale und die Stärke ihrer Ausprägung war früher nur durch trainierte Experten möglich. Heute kann dies mithilfe von Computeralgorithmen zu großen Teilen automatisch erfolgen. So ist beispielsweise die Open-Source-Bibliothek <a href=https://github.com/TadasBaltrusaitis/OpenFace>OpenFace</a> in der Lage, 18 AUs zu erkennen. Neben diesen AUs lassen sich mit der Bibliothek auch die Blickrichtung und die Kopfhaltung analysieren.<br><br>

                Basierend auf diesen Technologien entwickelt das Laboratory for Biosignal Processing Lösungen für spezifische Anwendungen und erschließt neue Anwendungsbereiche. Die Arbeiten hier sind daher ebenfalls ein wichtiger Baustein für das Themenfeld <a href=#headingSix> kontaklosen Schmerzmonitoring</a>.

                Darüber hinaus sind die hier durchgeführten Arbeiten wesentlicher Bestandteil unserer <a href=#headingTwelve>Software-Plattform zur Kamera-basierten Erfassung von Vitalparametern und Mimik</a>, deren Funktionalität Sie in einer <a href=#headingSixteen>Web-Applikation anhand eigener Videos selbst ausprobieren</a> können. Die Software wurde auch bereits in der Praxis für die <a href=#headingThirteen> Entwicklung eines digitalen Spiegels</a> verwendet.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingSix">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseSix" aria-expanded="false" aria-controls="collapseSix">
                  Kontaktloses Schmerzmonitoring
                </a>
              </h3>
            </div>
            <div id="collapseSix" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingSix">
              <div class="panel-body">
                <!--
                Migration der verschiedenen Modalitäten bzgl. Kamera-basierte Messung<br><br>

                Verwendung weiterer Modalitäten (Audio)<br><br>

                Bild OP?<br><br>


                <img src="img/Schmerzmonitoring.jpg" style="display:block;margin-left:auto;margin-right:auto;">

                Mehr zu diesem Themenfeld erfahren Sie hier in Kürze. Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingNine">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseNine" aria-expanded="false" aria-controls="collapseNine">
                  Entwicklung von Sensorsystemen
                </a>
              </h3>
            </div>
            <div id="collapseNine" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingNine">
              <div class="panel-body">
                <!--
                Sowohl Kamera-basierte Systeme als auch sensorbasiert<br><br>

                z.B. Kamera-basiertes und sensorbasiertes Objekttracking<br><br>

                <h2>Sensorik zur Messung von Biosignalen und Vitalparametern</h2>

                Peripherphysiologische Signale, also alle physiologischen Signale, die nicht direkt vom Gehirn erzeugt werden, geben in erster Linie Auskunft über den funktionellen Zustand des entsprechenden Organs bzw. Gewebes. Die Signale lassen sich als physikalische Größen an der Hautoberfläche direkt oder indirekt messen. Zu ihnen gehören unter anderem die elektrische Herzaktivität (das Elektrokardiogramm, EKG), die Atemfrequenz und der Hautleitwert. <br><br>

                Die Erfassung dieser Signale spielt in der medizinischen Diagnostik seit vielen Jahren eine bedeutende Rolle und gehört seit Jahrzehnten zur gängigen Praxis. Zur Erforschung neuartiger Behandlungsmöglichkeiten von Krankheiten benötigen Mediziner und Psychologen jedoch oft Systeme mit speziellen Eigenschaften, beispielsweise mit besonders hoher Signalqualität, spezillen Datenschnittstellen oder auch besondere mobile Lösungen.<br><br>

                Am Laboratory for Biosignal Processing entwickeln wir gemeinsam mit Anwendern und Partnern aus der Wirtschaft spezielle Messsysteme für unterschiedliche Einsatzbereiche. Beispielhaft dafür stehen ein <a href=#headingTwo> modulares, mobiles Biomonitoringsystem zur synchronen Erfassung unterschiedlicher  Biosignale und Vitalparameter</a> sowie ein <a href=#headingSeventeen> Messystem zur Erforschung des komplexen regionalen Schmerzsyndroms (engl.: Complex Regional Pain Syndrome, CRPS)</a>. <br><br>

                Mehr zu diesem Themenfeld erfahren Sie hier in Kürze. Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingEight">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseEight" aria-expanded="false" aria-controls="collapseEight">
                  Analyse von Vitalparametern & Gesundheitsdaten
                </a>
              </h3>
            </div>
            <div id="collapseEight" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingEight">
              <div class="panel-body">
                <!--
                Wir entwickeln Algorithmen; sowohl Signalgewinnung/Informationsgewinnung (z.B. Verfahren für Babyschreien/Weinen) als auch Analysen (z.B. Gesundheitszustand)<br><br>

                Mehr zu diesem Themenfeld erfahren Sie hier in Kürze. Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>


          <div class="panel-group" id="accordion" role="tablist" aria-multiselectable="true">
            <div class="panel panel-default">
              <div class="panel-heading" role="tab" id="headingOne">
                <h3 class="panel-title">
                  <a role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseOne" aria-expanded="false" aria-controls="collapseOne">
                    Echtzeitverarbeitung und -Quellenlokalisierung von EEG/MEG-Daten
                  </a>
                </h3>
              </div>
              <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
                <div class="panel-body">
                  Die Untersuchung und Erforschung des Gehirns ist ein wesentlicher Bestandteil der medizinischen Diagnostik, klinischen Forschung sowie verschiedenen neurowissenschaftlichen Disziplinen. Elektroenzephalografie (EEG) und Magnetenzephalografie (MEG) erfassen die bioelektrischen bzw. biomagnetischen Auswirkungen der Gehirnaktivität entweder als elektrische Potenzialänderungen auf der Kopfhaut oder als Änderungen der magnetischen Feldstärke in Kopfnähe.<br><br>

                  Auf Grund der hohen Rechenanforderungen sind bislang kaum EEG- und MEG-Geräte mit Online-Analyse-Software ausgestattet, um die aufgezeichneten Daten noch während der Messung zu analysieren und ggf. Rückschlüsse für den weiteren experimentellen Ablauf zu ziehen. Insbesondere die Online-Quellenrekonstruktion, das heißt die Bestimmung und Visualisierung der im Gehirn stattfindenen bioelektrischen Prozesse, gestaltet sich hier als besondere Herausforderung. Die Entwicklung solcher echtzeitfähiger Systeme ist deshalb Gegenstand aktueller Forschung. Sie sind die Grundlage für völlig neue Verfahren in der Kognitions- und der sozialen Neuroforschung und zur Optimierung des nicht selten zeitintensiven Messablaufs.<br><br>

                  <a href=#headingFifteen> Hier erfahren Sie mehr über die Ergebnisse unserer Forschungsarbeiten zu dieser Thematik.</a>

                </div>
              </div>
            </div>
          </div>
-->


          <h2>Ergebnisse & Anwendungsbeispiele</h2>
          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingSix">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseSix" aria-expanded="false" aria-controls="collapseSix">
                  Kontaktloses Schmerzmonitoring
                </a>
              </h3>
            </div>
            <div id="collapseSix" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingSix">
              <div class="panel-body">
                <!--
                Migration der verschiedenen Modalitäten bzgl. Kamera-basierte Messung<br><br>

                Verwendung weiterer Modalitäten (Audio)<br><br>

                Bild OP?<br><br>
		-->

                <img src="img/Schmerzmonitoring.jpg" style="display:block;margin-left:auto;margin-right:auto;">

                Mehr zu diesem Themenfeld erfahren Sie hier in Kürze. Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>


          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingTen">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseTen" aria-expanded="false" aria-controls="collapseTen">
                  Ergonomics in Motion: Echtzeit-Ergonomieanalyse und -visualisierung
                </a>
              </h3>
            </div>
            <div id="collapseTen" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTen">
              <div class="panel-body">
                Mehr zu diesem Anwendungsbeispiel erfahren Sie hier in Kürze. Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingEleven">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseEleven" aria-expanded="false" aria-controls="collapseEleven">
                  Web-Applikation: Extraktion von Skelettinformationen aus Videodaten
                </a>
              </h3>
            </div>
            <div id="collapseEleven" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingEleven">
              <div class="panel-body">
                Mehr zu diesem Anwendungsbeispiel erfahren Sie hier in Kürze. Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingNineteen">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseNineteen" aria-expanded="false" aria-controls="collapseNineteen">
                  Kontaktlose Erfassung von Vitalparametern bei Neugeborenen
                </a>
              </h3>
            </div>
            <div id="collapseNineteen" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingNineteen">
              <div class="panel-body">
                <!--
                BabyNEL-Ergebnisse einbetten<br><br>

                Template body Absatz 2<br><br>
              -->

              Im Themenfeld <a href=#headingFour>Kamera-basierte Erfassung von Vitalparametern</a> wurde am Laboratory for Biosignal Processing ein System zur kontaktlosen Vitalparametererfassung bei Neugeborenen entwickelt. Teile der Arbeiten wurden im Rahmen des Projektes "Entwicklung eines neuartigen Monitoring-Assistenzsystems für Babybetten" (Förderkennzeichen KF2042007KJ4) vom Bundesministerium für Wirtschaft und Energie gefördert. Zielstellung des Projektes war es, die  Kamera-basierte Vitalparametermessung im klinischen Umfeld zu realisieren.<br><br>

              Das zu diesem Zweck entwickelte prototypische mobile Messsystem besteht aus einer Industriekamera sowie mehrerer in einem Messkoffer installierter Komponenten wie PC, Display und Tastatur.
              <img src="img/babynel_messsystem.png" style="display:block;margin-left:auto;margin-right:auto;">

              Das System wurde im Rahmen einer Freiwilligenstudie eingetzt, um die kontaklose Messung von Vitalparametern mithilfe von Referenzdaten zu evaluieren, die mithilfe eines einfachen SpO2-Sensors bestimmt wurden. Das folgende Bild zeigt die Anbringung eines Referenz-SpO2-Sensors am Fuß eines Säuglings (links) sowie das vollständig aufgebaute Messsystem (rechts).
              <img src="img/babynel_kh.png" style="display:block;margin-left:auto;margin-right:auto;">

              <img src="img/babynel_sw2.png" style="display:block;margin-left:auto;margin-right:auto;">

              Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingTwelve">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseTwelve" aria-expanded="false" aria-controls="collapseTwelve">
                  Modulare Software zur Kamera-basierten Erfassung & Analyse von Mimik und Vitalparametern
                </a>
              </h3>
            </div>
            <div id="collapseTwelve" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwelve">
              <div class="panel-body">
                <!--
                BabyNEL-Ergebnisse einbetten<br><br>

                Template body Absatz 2<br><br>
              -->

              In den Themenfeldern <a href=#headingFour>Kamera-basierte Erfassung von Vitalparametern</a> und <a href=#headingFive>Kamera-basierte Erfassung von Mimik</a> wurde am Laboratory for Biosignal Processing die modulare Software <em>RemotePatientMonitor</em> zur Erfassung & Analyse von Vitalparametern und Mimik aus Kameradaten und Videofilmen entwickelt. Teile der Arbeiten wurden im Rahmen der Projekte "Entwicklung eines neuartigen Monitoring-Assistenzsystems für Babybetten" (Förderkennzeichen KF2042007KJ4) vom Bundesministerium für Wirtschaft und Energie vom Bundesministerium für Wirtschaft und Energie und "Nichtinvasive Erfassung und Analyse von Biosignalen zur unterstützenden Bewertung kritischer Vitalzustände" (13FH032IX5) vom Bundesministerium für Bildung und Forschung gefördert.<br><br>

              Grundsätzlich handelt es sich beim <em>RemotePatientMonitor</em> um ein C++-Framework, das durch seine modulare Architektur für verschiedene Anwendungen angepasst werden kann. Die Funktionalität umfasst die Aufnahme, Verarbeitung und Analyse von Videodaten, inesbondere die Extraktion von Herzfrequenz, Atemfrequenz, Blickrichtung und Action-Units zur Mimikbewertung.

              Teile der Software basieren auf der Open-Source-Bibliothek <a href=https://cmusatyalab.github.io/openface/>OpenFace</a>.


              <img src="img/rpm_software.png" style="display:block;margin-left:auto;margin-right:auto;">

              <img src="img/rpm_module.png" style="display:block;margin-left:auto;margin-right:auto;">

              Mehr zu diesem Anwendungsbeispiel erfahren Sie hier in Kürze. Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingSixteen">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseSixteen" aria-expanded="false" aria-controls="collapseSixteen">
                  Web-Applikation: Extraktion von Mimik- und Vitalparametern aus Videodaten
                </a>
              </h3>
            </div>
            <div id="collapseSixteen" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingSixteen">
              <div class="panel-body">
                Mehr zu diesem Anwendungsbeispiel erfahren Sie hier in Kürze. Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingThirteen">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseThirteen" aria-expanded="false" aria-controls="collapseThirteen">
                  Digitaler Spiegel mit eingebetteten Vitalinformationen
                </a>
              </h3>
            </div>
            <div id="collapseThirteen" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThirteen">
              <div class="panel-body">
                Mehr zu diesem Anwendungsbeispiel erfahren Sie hier in Kürze. Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingFourteen">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseFourteen" aria-expanded="false" aria-controls="collapseFourteen">
                  Mobiles Messystem zur Kontext-basierten Mimikerfassung
                </a>
              </h3>
            </div>
            <div id="collapseFourteen" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingFourteen">
              <div class="panel-body">
                <!--Marktforschungs-Cap<br><br>
                -->
                Mehr zu diesem Anwendungsbeispiel erfahren Sie hier in Kürze. Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingEightteen">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseEightteen" aria-expanded="false" aria-controls="collapseEightteen">
                  Kamera-basiertes Monitoring in Flächenreinigungsprozessen
                </a>
              </h3>
            </div>
            <div id="collapseEightteen" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingEightteen">
              <div class="panel-body">
                Mehr zu diesem Anwendungsbeispiel erfahren Sie hier in Kürze. Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingFifteen">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseFifteen" aria-expanded="false" aria-controls="collapseFifteen">
                  NA-Online-Toolbox: Software zur Echtzeit-Quellenlokalisierung von EEG/MEG-Daten
                </a>
              </h3>
            </div>
            <div id="collapseFifteen" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingFifteen">
              <div class="panel-body">
                Im Themenfeld <a href=#headingOne> Echtzeitverarbeitung und -Quellenlokalisierung von EEG/MEG-Daten</a> wurde am Laboratory for Biosignal Processing in Zusammenarbeit mit dem <a href=http://www.cbs.mpg.de>Max-Planck-Institut für Kognitions- und Neurowissenschaften</a> in Leipzig im Rahmen des vom Bundesministerium für Bildung und Forschung geförderten Projektes "Entwicklung eines Echtzeitsystems zur multimodalen Online-Auswertung neuronaler Aktivität auf Basis hochkanaliger EEG- und MEG-Daten" (NA-Online, Förderkennzeichen 17108X10) eine leistungsfähige, technisch stabile Systemlösung zur Online-Quellenrekonstruktion einschließlich der notwendigen Signalvorverarbeitungsalgorithmen entwickelt. Mit modernsten Parallelverarbeitungstechniken auf Basis von Grafikprozessoren in Verbindung mit effizienten Algorithmen wird so die Analyse der aufgenommenen EEG/MEG-Daten in Echtzeit ermöglicht. Die entwickelte Lösung kann in bestehende EEG- und MEG-Systeme integriert werden.<br><br>

                NA-Online Toolbox: <a target="_blank" href="https://github.com/labp/na-online_ow-toolbox">https://github.com/labp/na-online_ow-toolbox</a>

                <img src="img/na-online.png" style="display:block;margin-left:auto;margin-right:auto;">
                Das Bild zeigt einen Screenshot der NA-Onlne-Toolbox. Die einzelnen Blöcke der Signalverarbeitungskette (rechts oben) können individuell konfiguriert werden (rechts unten). Die vorverarbeiten EEG/MEG-Signale (links oben) können im Sensorraum dargestellt werden (links unten). Nach weiterer Verarbeitung und Mittelung der mehrerer Reizantworten auf den experimentellen Stimulus (Mitte oben) kann eine Quellenrekunstruktion während der Messung durchgeführt und auf der individuellen Gehirnoberfläche dargestellt werden (Mitte unten).<br><br>

                Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingTwo">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
                  Modulares Messsystem zur Erfassung von Biosignalen und Vitalparametern (Biomonitoringsystem)
                </a>
              </h3>
            </div>
            <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
              <div class="panel-body">
                Einer unserer F&E-Schwerpunkte ist die <a href=#headingNine> Entwicklung von Sensorsystemen</a>, in dessen Rahmen wir unter anderem unterschieldliche Sensorik und Sensorsysteme zur Messung von Biosignalen und Vitalparametern entwickeln. Ein Ergebnis dieser Arbeiten ist ein modulares Messsystem zur Erfassung von Biosignalen und Vitalparametern (Biomonitoringsystem). <br><br>

                Das Biomonitoringsystem wurde im Rahmen des vom Bundesministerium für Bildung und Forschung geförderten Verbundprojektes "Neue Methoden zur Echtzeit-Auswertung hochaufgelöster Messungen peripherphysiologischer Daten eines neuartigen modularen Messsystems " (PHYSIDAT, Förderkennzeichen 01EZ1024A) und des vom Bundesministerium für Wirtschaft und Energie geförderten Projektes "System zur simultanen Echtzeitmessung peripher-physiologischer Signale" (SEMEPS, Förderkennzeichen KF2180213KJ2) entwickelt. Es basiert auf einer modularen Systemarchitektur, bei der die Messung einzelner Signale in verschiedene Module ausgelagert ist und die Daten per Funkkommunikation an eine Basisstation übertragen werden. Die Basisstation stellt auch die Synchronisation der unterschiedlichen Module sicher.<br><br>
                <img src="img/bms_comm.png" style="display:block;margin-left:auto;margin-right:auto;">

                Mit Hilfe des Systems werden die peripherphysiologischen Signale simultan, in hoher Signalqualität und in Echtzeit erfasst. Das Messsystem ermöglicht dabei sowohl das Monitoring einzelner als auch die parallele Analyse mehrerer Patienten. Die modulare Zusammensetzung gewährleistet verschiedene Kombinationsmöglichkeiten für unterschiedliche Fragestellungen. Darüber hinaus steht das System als erweiterbare Plattform für weitere Einsatzgebiete zur Verfügung. Neben der Basisstation besteht das Biomonitoringsystem aus den im folgenden Bild dargestellten Modulen.<br><br>

                <img src="img/bms_system.png" style="display:block;margin-left:auto;margin-right:auto;">
                EKG-AF-Modul: Ableitung 12-Kanal-EKG und von 2 Atemkanälen (über Brust- und Bauchgurt); EDA-TEMP-Modul: Ableitung des Hautleitwertes (EDA) und der Hautoberflächentemperatur; EMG-Modul: Ableitung von 2 EMG-Kanälen (elektrisches Muskelaktivität, Elektromyogramm)<br><br>

                Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>

          <div class="panel panel-default">
            <div class="panel-heading" role="tab" id="headingSeventeen">
              <h3 class="panel-title">
                <a class="collapsed" role="button" data-toggle="collapse" data-parent="#accordion" href="#collapseSeventeen" aria-expanded="false" aria-controls="collapseSeventeen">
                  Messsystem zur Erforschung des Complex-Regional-Pain-Syndrome (CRPS)
                </a>
              </h3>
            </div>
            <div id="collapseSeventeen" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingSeventeen">
              <div class="panel-body">
                Einer unserer F&E-Schwerpunkte ist die <a href=#headingNine> Entwicklung von Sensorsystemen</a>, in dessen Rahmen wir unter anderem unterschieldliche Sensorik und Sensorsysteme zur Messung von Biosignalen und Vitalparametern entwickeln. Ein Ergebnis dieser Arbeiten ist ein Messsystem zur Erforschung des Complex-Regional-Pain-Syndrome (CRPS). <br><br>

                CRPS ist eine chronische neurologische Erkrankung, die als Symptome vor allem Durchblutungsstörungen, Ödeme, Hautveränderungen und starke Schmerzen verursacht. Forschungsergebnisse zeigen, dass die Analyse von Temperaturwerten der rechten und linken Körperhälfte im Vergleich zur Umgebungstemperatur einen Hinweise auf das
                Vorliegen von CRPS gibt (Krumanova et al., Long-term skin temperature measurements – A practical diagnostic tool in complex regional pain syndrome“, Pain 2008, 140(1), 8-22). Für eine Diagnose müssen diese Temperaturwerte daher mit einem geeigneten Messsystem bestimmt werden.<br><br>

                Am Laboratory for Biosignal Processing wurde im Rahmen des vom Bundesministerium für Wirtschaft und Energie geförderten Projektes "System zur simultanen Echtzeitmessung peripher-physiologischer Signale" (SEMEPS, Förderkennzeichen KF2180213KJ2) gemeinsam mit dem Projektparner <a href=http://www.mrc-systems.de/>MRC Systems GmbH</a> ein CRPS-Messsystem entwickelt. Das System besteht aus einer Masterstation und zwei Sensormodulen, mit denen jeweils zwei Temperatursignale abgeleitet werden können. Die Sensormodule werden i.d.R. am linken und rechten Handgelenk angebracht und sollen dabei die üblicherweise äußerst schmerzempfindlichen Patienten so wenig wie möglich belasten. Die anfallenden Daten werden per Funk an die Masterstation und damit an den Analyserechner übertragen.

                <img src="img/crps.jpg" style="display:block;margin-left:auto;margin-right:auto;">
                Das Bild zeigt das CRPS-Sensorsystem (rechts) und die Anbringung des Systems zur Messung der Hautoberflächentemperatur an Zeige- und Ringfinger (links).<br><br>

                Gern können Sie sich für Fragen auch direkt an uns wenden, <a href="#kontakt">nehmen Sie einfach Kontakt mit uns auf</a>.
              </div>
            </div>
          </div>
	</div>


<!--
      <h2>Kooperationspartner</h2>

          <a href="http://www.bmw-werk-leipzig.de" target="_blank"><img class="kooplogo" src="logo/BMWWerkLeipzig.png" /></a>
          <a href="http://www.conoscope.org" target="_blank"><img class="kooplogo" src="logo/conoscope.png" /></a>
          <a href="http://www.mrc-systems.de" target="_blank"><img class="kooplogo" src="logo/mrcsystems.png" /></a>
          <a href="http://www.nel.de" target="_blank"><img class="kooplogo" src="logo/nel.png" /></a>
          <a href="http://www.profi-con.com" target="_blank"><img class="kooplogo" src="logo/profi-con.png" /></a>
          <a href="http://leipzig-heart.de/" target="_blank"><img class="kooplogo" src="logo/LHI_logo.jpg" /></a>
          <a href="http://www.herzzentrum-leipzig.de" target="_blank"><img class="kooplogo" src="logo/Herzzentrum_Leipzig_logo.png" /></a>
          <!--<a href="http://leipzig-heart.de/" target="_blank"><img class="kooplogo" src="logo/LHI_logo.jpg" /></a>
          <a href="http://www.cbs.mpg.de/de" target="_blank"><img class="kooplogo" src="logo/logo_mpi-cbs.png" /></a>
          <a href="https://www.eva.mpg.de/index.html" target="_blank"><img class="kooplogo" src="logo/logo_mpi-eva.png" /></a>
          <a href="https://www.siemens.de" target="_blank"><img class="kooplogo" src="logo/siemens.png" /></a>
          <a href="http://www.uni.iat-leipzig.de" target="_blank"><img class="kooplogo" src="logo/iat-leipzig.png" /></a>
          <a href="https://www.uniklinikum-leipzig.de/" target="_blank"><img class="kooplogo" src="logo/uniklinik-leipzig.png" /></a>
-->
        </div>

      </section>

      <!=== Technologietransfer & Kooperationen==>
      <section id="technologietransfer" class="section">
        <div class="container">
          <h1>Technologietransfer & Kooperationen</h1>

          <h2>Unsere Ziele</h2>
          Forschungskooperationen zwischen Wissenschaft und Wirtschaft bilden eine entscheidende Grundlage für Innovationen und damit für die Wettbewerbsfähigkeit der Region.<br><br>

          Mit unserem Anspruch, anwendungsnahe und praxisrelevante Forschungsthemen zu bearbeiten, sind wir idealer Kooperationspartner für kleine, mittelständische und große Unternehmen.<br><br>

          Wir unterstützen Sie durch den Transfer von technologischem Know-how, externe Forschungs- und Entwicklungsleistungen, Machbarkeitsanalysen, Projektrealisierung sowie Beratung und Mitwirken bei der Beantragung von Fördermitteln. <br><br>

          Sie haben Interesse an einer Zusammenarbeit? Vereinbaren Sie bitte einen unverbindlichen Beratungstermin mit <a href="#kontakt">uns</a>.

          <h2>Unser Know-how</h2>
          Wir verfügen über umfangreiches Know-how in den Bereichen<br><br>

          <ul>
	    <li>Bildverarbeitung und -analyse, Computer Vision,</li>
            <li>Kamerabasierte Anwendungen,</li>
            <li>Maschinelles Lernen (ML) und Deep-Learning,</li>
	    <li>ML-basierte Sensordatenanalyse und Signalverarbeitung</li>
            <li>Eingebettete Systems und Echtzeitanwendungen</li>
            <li>Softwareentwicklung (C, C++, Qt, MATLAB, usw.) sowie</li>
            <li>Algorithmenentwicklung und Signalverarbeitung (Audio, Video).</li>
          </ul>

          In interdisziplinären Forschungs- und Entwicklungsprojekten mit Partnern aus vielfältigen Bereichen, u.a. Sport, Medizin, Biologie, Neurowissenschaften, Architektur und Bau, entwickeln wir innovative, anwendungsnahe Lösungen für vielfältige Problemstellungen. Wir können technische Lösungen bis zur Nullserie realisieren, die entweder zur Durchführung praxisnaher Tests verwendet oder durch Wissens- und Technologietransfer in Unternehmen verwertet werden können.<br>

<!--
          <div class="sponsor">
            <div class="logo">
              <a href="http://www.leipziger-stiftung.de" target="_blank"><img src="logo/LeipzigerStiftung.png" /></a>
            </div>
            <div class="text">
              Der Technologietransfer wird gefördert durch die <a target="_blank" href="http://www.leipziger-stiftung.de">Leipziger Stiftung für Innovation und Technologietransfer</a>.
            </div>
          </div>
-->
        </div>

		<div class="container">
	  	<h2>Kooperationspartner</h2>
		    <div class="koopcolumn">
		        <div class="kooprow">
		            <a href="https://www.kanu.de/" target="_blank"><img src="logo/DKV-Fahne farbig.gif" /></a>
		            <a href="https://sport-iat.de" target="_blank"><img src="logo/IAT_Logo_CMYK.png" /></a>
                    <a href="https://fes-sport.de/" target="_blank"><img src="logo/fes-logo-bk.png" /></a>
		        </div>
				<div class="kooprow">
					<a href="https://www.rudern.de/" target="_blank"><img src="logo/Deutscher_Ruderverband_Logo_2007.png" /></a>
		  		    <a href="https://www.dhb.de/" target="_blank"><img src="logo/Deutscher_Handballbund_Logo_RGB.png" /></a>
	            </div>
				<div class="kooprow">
					<a href="https://www.bmwgroup-werke.com/leipzig/de.html" target="_blank"><img src="logo/BMWWerkLeipzig.png" /></a>
	      	        <a href="https://www.siemens.de" target="_blank"><img src="logo/siemens.png" /></a>
	      	        <a href="https://www.conoscope.de/" target="_blank"><img src="logo/conoscope.png" /></a>
	            </div>
				<div class="kooprow">
					<a href="https://www.mrc-systems.de/" target="_blank"><img src="logo/mrcsystems.png" /></a>
	      	        <a href="https://www.nel.de/" target="_blank"><img src="logo/nel.png" /></a>
	      	        <a href="https://www.cws.com/en/cleanroom/cleanroom-cleaning" target="_blank"><img src="logo/profi-con.png" /></a>
	            </div>
				<div class="kooprow">
					<a href="https://www.sport.uni-halle.de/arbeitsbereiche/bewegungswissenschaft/" target="_blank"><img src="logo/MLU_Doppelsiegel-zentriert_2020.png" /></a>
		  		    <a href="https://www.spowi.uni-leipzig.de/bewegungsneurowissenschaft" target="_blank"><img src="logo/Universität_Leipzig_logo.png" /></a>
		  	    </div>
				<div class="kooprow">
					<a href="https://www.cbs.mpg.de/de" target="_blank"><img src="logo/logo_mpi-cbs.png" /></a>
	      	        <a href="https://www.eva.mpg.de/index.html" target="_blank"><img src="logo/logo_mpi-eva.png" /></a>
	            </div>
				<div class="kooprow">
					<a href="https://www.helios-gesundheit.de/index.php?id=5672" target="_blank"><img src="logo/Herzzentrum_Leipzig_logo.png" /></a>
	      	        <a href="https://www.helios-gesundheit.de/standorte-angebote/firmenkunden/hhi/" target="_blank"><img src="logo/LHI_logo.jpg" /></a>
	      	        <a href="https://www.uniklinikum-leipzig.de/" target="_blank"><img src="logo/uniklinik-leipzig.png" /></a>
				</div>
			</div>			  
		</div>
      </section>

      <!=== Team ==>
      <section id="team" class="section">
        <div class="container">
          <h1>Team</h1>
<!--
          <div class="portrait">
            <img src="./team/sturm.png">
            <div class="info">
              <h3>Prof. Dr.-Ing. Matthias Sturm</h3>
              <strong>Arbeitsgruppenleiter</strong><br>
              Tel. +49 341 3076 3116<br>
              <script>document.write(mailAddress("matthias", "sturm"));</script>
            </div>
          </div>
-->
<!--
          <div class="portrait">
            <img src="./team/bausch.png">
            <div class="info">
              <h3>Prof. Dr.-Ing. Gerold Bausch</h3>
              <strong>Eingebettete Systeme und Signalverarbeitung</strong><br>
              Tel. +49 341 3076 3103<br>
              <script>document.write(mailAddress("gerold", "bausch"));</script>&nbsp;(<a href="bausch.asc">GPG-Key</a>)<br>
              <a href="https://www.xing.com/profile/Gerold_Bausch" target="_blank"><i class="fa fa-xing-square fa-2x" aria-hidden="true"></i></a>&nbsp;
              <a href="http://linkedin.com/in/gerold-bausch-23239816" target="_blank"><i class="fa fa-linkedin-square fa-2x" aria-hidden="true"></i></a>
            </div>
          </div>
-->

          <div class="portrait">
            <img src="./team/fuchs.png">
            <div class="info">
              <h3>Prof. Dr.-Ing. Mirco Fuchs</h3>
              <strong>Wissenschaftlicher Leiter</strong><br>
              Tel. +49 341 3076 3104<br>
              <script>document.write(mailAddress("mirco", "fuchs"));</script>&nbsp;(<a href="fuchs.asc">GPG-Key</a>)<br>
	      <a href="https://www.xing.com/profile/Mirco_Fuchs" target="_blank"><i class="fa fa-xing-square fa-2x" aria-hidden="true"></i></a>&nbsp;
            </div>
          </div>

          <div class="portrait">
            <img src="./team/nobody_w.png">
            <div class="info">
              <h3>Michaela Hahn</h3>
              <strong>Forschungsassistenz</strong><br>
              Tel. +49 341 3076 3100<br>
              <script>document.write(mailAddress("michaela","hahn"));</script>
            </div>
          </div>

          <div class="portrait">
            <img src="./team/frenzel.png">
            <div class="info">
              <h3>Patrick Frenzel, M.Sc.</h3>
              <strong>Wissenschaftlicher Mitarbeiter</strong><br>
              Tel. +49 341 3076 3130<br>
              <script>document.write(mailAddress("patrick", "frenzel"));</script>
            </div>
          </div>

<!--
          <div class="portrait">
            <img src="./team/schrumpf.png">
            <div class="info">
              <h3>Dr.-Ing. Fabian Schrumpf</h3>
              <strong>Wissenschaftlicher Mitarbeiter</strong><br>
              Tel. +49 341 3076 3152<br>
              <script>document.write(mailAddress("fabian", "schrumpf"));</script>
            </div>
          </div>
-->

          <div class="portrait">
            <img src="./team/matthes.png">
            <div class="info">
              <h3>Daniel Matthes, M.Sc.</h3>
              <strong>Wissenschaftlicher Mitarbeiter</strong><br>
	      Tel. +49 341 3076 3208<br>
              <script>document.write(mailAddress("daniel", "matthes"));</script>
            </div>
          </div>

          <div class="portrait">
            <img src="./team/reichard.png">
            <div class="info">
              <h3>Bianca Reichard, M.Sc.</h3>
              <strong>Doktorandin</strong><br>
              <script>document.write(mailAddressStud("bianca", "reichard"));</script>
            </div>
          </div>
		
	 <div class="portrait">
           <img src="./team/sobisch.png">
           <div class="info">
             <h3>Jannik Sobisch, M.Sc.</h3>
              <strong>Doktorand, Wissenschaftlicher Mitarbeiter</strong><br>
	      <script>document.write(mailAddress("jannik", "sobisch"));</script>	   
           </div>
         </div>
		
         <div class="portrait">
           <img src="./team/ziegler.png">
           <div class="info">
             <h3>Julian Thomas Ziegler, B.Sc.</h3>
              <strong>Masterstudent, Wissenschaftlicher Mitarbeiter</strong><br>
	      <script>document.write(mailAddress("julian_thomas", "ziegler"));</script>		   
           </div>
         </div>

         <div class="portrait">
           <img src="./team/nobody_w.png">
           <div class="info">
             <h3>Paula Schlegel</h3>
              <strong>Masterstudentin</strong><br>
           </div>
         </div>

	<div class="portrait">
           <img src="./team/nobody_m.png">
           <div class="info">
             <h3>Paul Jürgens</h3>
              <strong>Masterstudent</strong><br>
           </div>
        </div>

	<div class="portrait">
           <img src="./team/nobody_m.png">
           <div class="info">
             <h3>Toni Volker Schoechert</h3>
              <strong>Bachelorstudent</strong><br>
           </div>
        </div>

	<div class="portrait">
           <img src="./team/nobody_m.png">
           <div class="info">
             <h3>Michael Francisco Bäumler</h3>
              <strong>Bachelorstudent</strong><br>
           </div>
        </div>		

        <!-- TODO:
        * Studenten bzw. studentische Hilfskräfte aufnehmen
        * Sektion mit ehemaligen Mitarbeitern einfügen
        -->
        </div>
      </section>



      <!=== Kontakt ==>
      <section id="kontakt" class="section">
        <div class="container center">
          <h1>Nehmen Sie Kontakt mit uns auf</h1>

          Hochschule für Technik, Wirtschaft und Kultur (HTWK) Leipzig,<br> Forschungszentrum Life Science &amp; Engineering<br><br><br>

          <div class="column">
            <strong>Post:</strong><br />
            HTWK Leipzig<br />
            c/o Laboratory for Biosignal Processing<br />
            Forschungszentrum LSE<br />
            Postfach 30 11 66<br />
            04251 Leipzig<br /><br />
          </div>

          <div class="column">
            <strong>Besucher:</strong><br />
            HTWK Leipzig<br />
            <!--Laboratory for Biosignal Processing<br />-->
            Forschungszentrum LSE<br />
            Eilenburger Straße 13<br />
            04317 Leipzig<br /><br />
          </div>

          <div class="column">
           	<strong>Ansprechpartner:</strong><br />

            Prof. Dr.-Ing. Mirco Fuchs<br />
            Wissenschaftlicher Leiter<br />
            E-Mail: mirco.fuchs@htwk-leipzig.de<br />
            Tel. +49 341 3076 3104<br /><br />
          </div>

          <div id="map" style="height:380px; width:100%"></div>

        </div>
      </section>

    </div> <!-- container -->
  </div> <!-- main -->

  <!=== Footer ==>
  <div id="footer" class="section text-white">
    <div class="container">
      <p>
        &copy; 2014&ndash;2022 Laboratory for Biosignal Processing, HTWK Leipzig, University of Applied Sciences.
        <a href="https://www.htwk-leipzig.de/hochschule/kontakt/impressum/" target="_blank">Impressum</a>
      </p>
    </div>
  </div>

</div>

<!--
<script>
  L.mapbox.accessToken = 'pk.eyJ1IjoiZ2JhdXNjaCIsImEiOiJpVHRrSDR3In0.KElm6gZZFPFNiBB0GQ0iQg';

  var map = L.mapbox.map('map', 'gbausch.li1b311k')
  .setView([51.3335,12.4006], 17);

    // Build a marker from a simple GeoJSON object:
    var marker = L.mapbox.featureLayer({
      type: 'Feature',
      geometry: {
        type: 'Point',
        coordinates: [12.40060299999999,51.333158]
      },
      properties: {
        title: 'Laboratory for Biosignal Processing',
        description: 'Eilenburger Straße 13,<br>04317 Leipzig',
        'marker-color': '#29A9E7',
        'marker-symbol': 'circle',
        'marker-size': 'large',
      }
    }).addTo(map);

    marker.eachLayer(function(m) {
      m.openPopup();
    });

    map.touchZoom.disable();
    map.scrollWheelZoom.disable();

  </script>

  <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
  <!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>-->
  <script src="./js/jquery-1.11.2.min.js"></script>
  <script src="./js/site.js"></script>
  <script src="./js/bootstrap.min.js"></script>

-->

  <!-- Google Analytics -->
  <!--
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-65088015-2', 'auto');
  ga('send', 'pageview');
  </script>
  -->
  <!-- End Google Analytics -->

</body>
</html>
